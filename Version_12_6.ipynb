{
 "metadata": {
  "name": "",
  "signature": "sha256:d36f8b9ec85ad705798e4af5ec1794b067b2abcb8a93417d1f7f012871dc78d8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, zipfile, StringIO\n",
      "import pandas as pd\n",
      "from pandas import DataFrame, read_csv\n",
      "import math\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#urls for Voting registration by Sex, Race and Hispanic Origin, for States \n",
      "url_2012 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2012/Table04b.csv'\n",
      "url_2010 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2010/Table4b_2010.csv'\n",
      "url_2008 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2008/Table%2004b.csv'\n",
      "url_2006 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2006/tab04b.csv'\n",
      "url_2004 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04a.csv'\n",
      "url_2002 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2002/tab04a.csv'\n",
      "urllist=[url_2012, url_2010, url_2008, url_2006, url_2004, url_2002]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Combines datasets to create dataframe of state/year rows\n",
      "#TOTAL VOTER INCLUDES NON CITIZENS (BOTH 18+)\n",
      "#WE'RE WORKING WITH CITIZENS\n",
      "\n",
      "#iterate through years\n",
      "for year in [2012, 2010, 2008, 2006, 2004, 2002]:\n",
      "    \n",
      "    #create dataframe\n",
      "    url=urllist[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    table['Year'] = year #create year column\n",
      "    \n",
      "    #create large dataframe\n",
      "    #each year needs own case b/c original tables formatted differently; combined to reuse code wherever possible \n",
      "    \n",
      "    if year==2012:\n",
      "        changeCol=dict(zip(table.columns, table.ix[2,:])) #change the columns to match what we want them to be \n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True)\n",
      "        table=table[table.index < 572] #we don't want first or last few rows\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        state = [] #initialize state array to use later\n",
      "        for i in range(52): #create state column\n",
      "            table[11*i:11*(i+1)]['State'] = table.ix[11*i]['State']\n",
      "            state.append(table.ix[11*i]['State']) #append to state array\n",
      "        df=table\n",
      "        df.columns=['State', 'Race and Hispanic origin', 'Total Population', 'Total Citizen Population', 'Total registered', 'Percent registered\\n(Total)', 'Margin of Error1', 'Percent registered\\n(Citizen)', 'Margin of Error2', 'Total voted', 'Percent voted\\n(Total)', 'Margin of Error3', 'Percent voted\\n(Citizen)', 'Margin of Error4', 'Year']\n",
      "            #rename columns\n",
      "            \n",
      "    elif year==2010:\n",
      "        table.ix[1, 1]='Race and Hispanic origin'\n",
      "        colnames=dict(zip(table.columns, table.ix[1,:]))#not analagous for years\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True) #also not analagous\n",
      "        table=table[table.index < 572]\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0, 0]='All'\n",
      "        for i in range(52):\n",
      "            table[11*i:11*(i+1)]['STATE'] = table.ix[11*i]['STATE']\n",
      "        table.columns = df.columns #rename columns\n",
      "        df = pd.concat([table,df]) #concat w/ dataframe\n",
      "    \n",
      "    elif (year==2008)|(year==2006)|(year==2004)|(year==2002):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        colnames=dict(zip(table.columns, table.ix[4,:]))\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0,0]='All'\n",
      "       \n",
      "        if (year==2008)|(year==2006):\n",
      "            table.columns=df.columns[1:15]\n",
      "            table['State']='nan'\n",
      "            for i in range(52):      \n",
      "                table[12*i:12*(i+1)]['State'] = table.ix[12*i]['Race and Hispanic origin']   \n",
      "            #delete every 12th row starting from first\n",
      "        \n",
      "        elif (year==2004)|(year==2002):\n",
      "            table=table.iloc[:,[0,1,2,5,6,7,8,9,10,11]] #delete useless columns\n",
      "            table.columns=df.columns[[1,2,3,4,5,6,9,10,11,14]] #name columns appropriately\n",
      "            table['Percent registered\\n(Citizen)']='nan' #create missing columns\n",
      "            table['Margin of Error2']='nan'\n",
      "            table['Percent voted\\n(Citizen)']='nan'\n",
      "            table['Margin of Error4']='nan'\n",
      "            table['State']='nan'\n",
      "            \n",
      "            if year==2004:\n",
      "                table=table.drop([43]).reset_index(drop=True) #one state has a duplicate row        \n",
      "                for i in range(49): #something weird - don't have data for all states in 2004 (missing West Virginia, Wymoning, Wisconsin?)\n",
      "                    table[13*i:13*(i+1)]['State'] = table.ix[13*i]['Race and Hispanic origin']\n",
      "            \n",
      "            elif year==2002:\n",
      "                for i in range(52):\n",
      "                    table[10*i:10*(i+1)]['State'] = table.ix[10*i]['Race and Hispanic origin']\n",
      "        \n",
      "        table = table[df.columns]\n",
      "        df = pd.concat([table,df])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 657: expected 13 fields, saw 24\n",
        "Skipping line 658: expected 13 fields, saw 24\n",
        "Skipping line 659: expected 13 fields, saw 24\n",
        "Skipping line 660: expected 13 fields, saw 24\n",
        "Skipping line 661: expected 13 fields, saw 24\n",
        "Skipping line 662: expected 13 fields, saw 24\n",
        "Skipping line 663: expected 13 fields, saw 24\n",
        "Skipping line 664: expected 13 fields, saw 24\n",
        "Skipping line 665: expected 13 fields, saw 24\n",
        "Skipping line 666: expected 13 fields, saw 24\n",
        "Skipping line 667: expected 13 fields, saw 24\n",
        "Skipping line 668: expected 13 fields, saw 24\n",
        "Skipping line 669: expected 13 fields, saw 24\n",
        "Skipping line 670: expected 13 fields, saw 24\n",
        "Skipping line 671: expected 13 fields, saw 24\n",
        "Skipping line 672: expected 13 fields, saw 24\n",
        "Skipping line 673: expected 13 fields, saw 37\n",
        "Skipping line 674: expected 13 fields, saw 37\n",
        "Skipping line 675: expected 13 fields, saw 37\n",
        "Skipping line 676: expected 13 fields, saw 37\n",
        "Skipping line 677: expected 13 fields, saw 37\n",
        "Skipping line 678: expected 13 fields, saw 37\n",
        "Skipping line 679: expected 13 fields, saw 37\n",
        "Skipping line 680: expected 13 fields, saw 37\n",
        "Skipping line 681: expected 13 fields, saw 37\n",
        "Skipping line 682: expected 13 fields, saw 37\n",
        "Skipping line 683: expected 13 fields, saw 37\n",
        "Skipping line 684: expected 13 fields, saw 37\n",
        "Skipping line 685: expected 13 fields, saw 37\n",
        "Skipping line 686: expected 13 fields, saw 37\n",
        "Skipping line 687: expected 13 fields, saw 37\n",
        "Skipping line 688: expected 13 fields, saw 37\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#THIS SHOULD BE MADE MORE ACCURATE IF SOMEONE IS BORED\n",
      "\n",
      "#http://www.ncsl.org/research/elections-and-campaigns/voter-id-history.aspx\n",
      "    #0 = no voter id law\n",
      "    #1 = not strict voter id law (w/ or w/out photo)\n",
      "    #2 = strict voter id law (w/ or w/out photo)\n",
      "#http://en.wikipedia.org/wiki/Voter_ID_laws_in_the_United_States\n",
      "#http://www.hartwick.edu/Documents/POSC/MeyerThesisSp13.pdf -- not completely synced with this source\n",
      "\n",
      "law_id=pd.DataFrame(columns=['State','non_strict_year', 'strict_year'])\n",
      "law_id['State'] = state[1:52]\n",
      "\n",
      "law_id.ix[0,1] = 2003\n",
      "law_id.ix[1,1] = 1980\n",
      "law_id.ix[2,2] = 2004 #check wiki article date: 2006?\n",
      "law_id.ix[5,1] = 2003\n",
      "law_id.ix[6,1] = 2010\n",
      "law_id.ix[7,1] = 2010\n",
      "law_id.ix[9,1] = 1977\n",
      "law_id.ix[10,[1,2]] = [1997,2008]\n",
      "law_id.ix[11,1] = 1970\n",
      "law_id.ix[12,1] = 2010\n",
      "law_id.ix[14,2] = 2008\n",
      "law_id.ix[16,2] = 2011\n",
      "law_id.ix[18,1] = 2010\n",
      "law_id.ix[22,1] = 2010\n",
      "law_id.ix[24,2] = 2012\n",
      "law_id.ix[25,1] = 2002\n",
      "law_id.ix[26,1] = 2003\n",
      "law_id.ix[29,1] = 2012\n",
      "law_id.ix[33,2] = 2016\n",
      "law_id.ix[34,[1,2]] = [2003,2013]\n",
      "law_id.ix[35,2] = 2006\n",
      "law_id.ix[36,1] = 2010\n",
      "law_id.ix[39,1] = 2013\n",
      "law_id.ix[40,[1,2]] = [1950,2013]\n",
      "law_id.ix[41,1] = 2003\n",
      "law_id.ix[42,[1,2]] = [1990,2011]\n",
      "law_id.ix[43,1] = 1971\n",
      "law_id.ix[44,1] = 2009\n",
      "law_id.ix[46,[1,2]] = [1996,2013]\n",
      "law_id.ix[47,1] = 2005"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "racedata = pd.merge(df, law_id, on = ['State'])\n",
      "\n",
      "#boolean shtuff\n",
      "racedata['status'] = 2 * (racedata['strict_year']<racedata['Year']).astype(int) + (racedata['non_strict_year']<racedata['Year']).astype(int) \n",
      "\n",
      "#Change 3's to 2's to make up for the fact that we added states that had both strict and non strict id laws twice\n",
      "for row in racedata.index:\n",
      "    if racedata.ix[row,'status'] == 3:\n",
      "        racedata.ix[row,'status'] = 2\n",
      "        \n",
      "racedata.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>State</th>\n",
        "      <th>Race and Hispanic origin</th>\n",
        "      <th>Total Population</th>\n",
        "      <th>Total Citizen Population</th>\n",
        "      <th>Total registered</th>\n",
        "      <th>Percent registered\n",
        "(Total)</th>\n",
        "      <th>Margin of Error1</th>\n",
        "      <th>Percent registered\n",
        "(Citizen)</th>\n",
        "      <th>Margin of Error2</th>\n",
        "      <th>Total voted</th>\n",
        "      <th>Percent voted\n",
        "(Total)</th>\n",
        "      <th>Margin of Error3</th>\n",
        "      <th>Percent voted\n",
        "(Citizen)</th>\n",
        "      <th>Margin of Error4</th>\n",
        "      <th>Year</th>\n",
        "      <th>non_strict_year</th>\n",
        "      <th>strict_year</th>\n",
        "      <th>status</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                     ALABAMA</td>\n",
        "      <td>      </td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                      .Total</td>\n",
        "      <td> 3,252</td>\n",
        "      <td> 3,215</td>\n",
        "      <td> 2,347</td>\n",
        "      <td> 72.2</td>\n",
        "      <td> 2.2</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 1,585</td>\n",
        "      <td> 48.7</td>\n",
        "      <td> 2.4</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                       .Male</td>\n",
        "      <td> 1,520</td>\n",
        "      <td> 1,503</td>\n",
        "      <td> 1,059</td>\n",
        "      <td> 69.6</td>\n",
        "      <td> 3.2</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   755</td>\n",
        "      <td> 49.7</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                     .Female</td>\n",
        "      <td> 1,732</td>\n",
        "      <td> 1,712</td>\n",
        "      <td> 1,288</td>\n",
        "      <td> 74.4</td>\n",
        "      <td> 2.9</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   829</td>\n",
        "      <td> 47.9</td>\n",
        "      <td> 3.3</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>         .Non-Hispanic White</td>\n",
        "      <td> 2,421</td>\n",
        "      <td> 2,402</td>\n",
        "      <td> 1,798</td>\n",
        "      <td> 74.2</td>\n",
        "      <td> 2.4</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 1,242</td>\n",
        "      <td> 51.3</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>         .Non-Hispanic Black</td>\n",
        "      <td>   776</td>\n",
        "      <td>   776</td>\n",
        "      <td>   524</td>\n",
        "      <td> 67.6</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   336</td>\n",
        "      <td> 43.3</td>\n",
        "      <td> 5.9</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td> .Asian and Pacific Islander</td>\n",
        "      <td>    23</td>\n",
        "      <td>    18</td>\n",
        "      <td>    13</td>\n",
        "      <td>  (B)</td>\n",
        "      <td> (B)</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>     6</td>\n",
        "      <td>  (B)</td>\n",
        "      <td> (B)</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>     .Hispanic (of any race)</td>\n",
        "      <td>    30</td>\n",
        "      <td>    17</td>\n",
        "      <td>    10</td>\n",
        "      <td>  (B)</td>\n",
        "      <td> (B)</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>     -</td>\n",
        "      <td>  (B)</td>\n",
        "      <td> (B)</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                      .White</td>\n",
        "      <td> 2,452</td>\n",
        "      <td> 2,419</td>\n",
        "      <td> 1,807</td>\n",
        "      <td> 73.7</td>\n",
        "      <td> 2.4</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 1,242</td>\n",
        "      <td> 50.7</td>\n",
        "      <td> 2.8</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                      .Black</td>\n",
        "      <td>   776</td>\n",
        "      <td>   776</td>\n",
        "      <td>   524</td>\n",
        "      <td> 67.6</td>\n",
        "      <td> 5.6</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   336</td>\n",
        "      <td> 43.3</td>\n",
        "      <td> 5.9</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2002</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                     ALABAMA</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2004</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                      .Total</td>\n",
        "      <td> 3,332</td>\n",
        "      <td> 3,257</td>\n",
        "      <td> 2,418</td>\n",
        "      <td> 72.6</td>\n",
        "      <td> 2.1</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2,060</td>\n",
        "      <td> 61.8</td>\n",
        "      <td> 2.3</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2004</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                       .Male</td>\n",
        "      <td> 1,568</td>\n",
        "      <td> 1,521</td>\n",
        "      <td> 1,109</td>\n",
        "      <td> 70.7</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td>   935</td>\n",
        "      <td> 59.6</td>\n",
        "      <td> 3.4</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2004</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                     .Female</td>\n",
        "      <td> 1,764</td>\n",
        "      <td> 1,736</td>\n",
        "      <td> 1,309</td>\n",
        "      <td> 74.2</td>\n",
        "      <td> 2.9</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 1,125</td>\n",
        "      <td> 63.8</td>\n",
        "      <td> 3.1</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2004</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> ALABAMA</td>\n",
        "      <td>                .White alone</td>\n",
        "      <td> 2,450</td>\n",
        "      <td> 2,400</td>\n",
        "      <td> 1,808</td>\n",
        "      <td> 73.8</td>\n",
        "      <td> 2.4</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 1,523</td>\n",
        "      <td> 62.2</td>\n",
        "      <td> 2.7</td>\n",
        "      <td> nan</td>\n",
        "      <td> nan</td>\n",
        "      <td> 2004</td>\n",
        "      <td> 2003</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "      State     Race and Hispanic origin Total Population  \\\n",
        "0   ALABAMA                      ALABAMA                    \n",
        "1   ALABAMA                       .Total            3,252   \n",
        "2   ALABAMA                        .Male            1,520   \n",
        "3   ALABAMA                      .Female            1,732   \n",
        "4   ALABAMA          .Non-Hispanic White            2,421   \n",
        "5   ALABAMA          .Non-Hispanic Black              776   \n",
        "6   ALABAMA  .Asian and Pacific Islander               23   \n",
        "7   ALABAMA      .Hispanic (of any race)               30   \n",
        "8   ALABAMA                       .White            2,452   \n",
        "9   ALABAMA                       .Black              776   \n",
        "10  ALABAMA                      ALABAMA              NaN   \n",
        "11  ALABAMA                       .Total            3,332   \n",
        "12  ALABAMA                        .Male            1,568   \n",
        "13  ALABAMA                      .Female            1,764   \n",
        "14  ALABAMA                 .White alone            2,450   \n",
        "\n",
        "   Total Citizen Population Total registered Percent registered\\n(Total)  \\\n",
        "0                       NaN              NaN                         NaN   \n",
        "1                     3,215            2,347                        72.2   \n",
        "2                     1,503            1,059                        69.6   \n",
        "3                     1,712            1,288                        74.4   \n",
        "4                     2,402            1,798                        74.2   \n",
        "5                       776              524                        67.6   \n",
        "6                        18               13                         (B)   \n",
        "7                        17               10                         (B)   \n",
        "8                     2,419            1,807                        73.7   \n",
        "9                       776              524                        67.6   \n",
        "10                      NaN              NaN                         NaN   \n",
        "11                    3,257            2,418                        72.6   \n",
        "12                    1,521            1,109                        70.7   \n",
        "13                    1,736            1,309                        74.2   \n",
        "14                    2,400            1,808                        73.8   \n",
        "\n",
        "   Margin of Error1 Percent registered\\n(Citizen) Margin of Error2  \\\n",
        "0               NaN                           nan              nan   \n",
        "1               2.2                           nan              nan   \n",
        "2               3.2                           nan              nan   \n",
        "3               2.9                           nan              nan   \n",
        "4               2.4                           nan              nan   \n",
        "5               5.6                           nan              nan   \n",
        "6               (B)                           nan              nan   \n",
        "7               (B)                           nan              nan   \n",
        "8               2.4                           nan              nan   \n",
        "9               5.6                           nan              nan   \n",
        "10              NaN                           nan              nan   \n",
        "11              2.1                           nan              nan   \n",
        "12              3.1                           nan              nan   \n",
        "13              2.9                           nan              nan   \n",
        "14              2.4                           nan              nan   \n",
        "\n",
        "   Total voted Percent voted\\n(Total) Margin of Error3  \\\n",
        "0          NaN                    NaN              NaN   \n",
        "1        1,585                   48.7              2.4   \n",
        "2          755                   49.7              3.5   \n",
        "3          829                   47.9              3.3   \n",
        "4        1,242                   51.3              2.8   \n",
        "5          336                   43.3              5.9   \n",
        "6            6                    (B)              (B)   \n",
        "7            -                    (B)              (B)   \n",
        "8        1,242                   50.7              2.8   \n",
        "9          336                   43.3              5.9   \n",
        "10         NaN                    NaN              NaN   \n",
        "11       2,060                   61.8              2.3   \n",
        "12         935                   59.6              3.4   \n",
        "13       1,125                   63.8              3.1   \n",
        "14       1,523                   62.2              2.7   \n",
        "\n",
        "   Percent voted\\n(Citizen) Margin of Error4  Year non_strict_year  \\\n",
        "0                       nan              nan  2002            2003   \n",
        "1                       nan              nan  2002            2003   \n",
        "2                       nan              nan  2002            2003   \n",
        "3                       nan              nan  2002            2003   \n",
        "4                       nan              nan  2002            2003   \n",
        "5                       nan              nan  2002            2003   \n",
        "6                       nan              nan  2002            2003   \n",
        "7                       nan              nan  2002            2003   \n",
        "8                       nan              nan  2002            2003   \n",
        "9                       nan              nan  2002            2003   \n",
        "10                      nan              nan  2004            2003   \n",
        "11                      nan              nan  2004            2003   \n",
        "12                      nan              nan  2004            2003   \n",
        "13                      nan              nan  2004            2003   \n",
        "14                      nan              nan  2004            2003   \n",
        "\n",
        "   strict_year  status  \n",
        "0          NaN       0  \n",
        "1          NaN       0  \n",
        "2          NaN       0  \n",
        "3          NaN       0  \n",
        "4          NaN       0  \n",
        "5          NaN       0  \n",
        "6          NaN       0  \n",
        "7          NaN       0  \n",
        "8          NaN       0  \n",
        "9          NaN       0  \n",
        "10         NaN       1  \n",
        "11         NaN       1  \n",
        "12         NaN       1  \n",
        "13         NaN       1  \n",
        "14         NaN       1  "
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.patches as mpatches\n",
      "statedata = racedata.groupby('State').get_group('ALABAMA')\n",
      "subgroup = statedata.groupby('Race and Hispanic origin').get_group('.Total')\n",
      "subgroup2 = statedata.groupby('Race and Hispanic origin').get_group('.Non-Hispanic White')\n",
      "\n",
      "tot = plt.scatter(x = subgroup['Year'], y = subgroup['Percent registered\\n(Total)'], c = 'b')\n",
      "white = plt.scatter(x = subgroup2['Year'], y = subgroup2['Percent registered\\n(Total)'], c = 'g')\n",
      "\n",
      "plt.xlim(2000,2014)\n",
      "\n",
      "plt.legend((tot, white), ('All groups', 'White'), scatterpoints=1,)\n",
      "plt.show()\n",
      "\n",
      "#red_patch = mpatches.Patch(label='The red data')\n",
      "#plt.legend(color = 'red', handles=[red_patch])\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJEmSJEmSJEmSGu7/A5QJxAORjMD1AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a815190>"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MAKES DICTIONARY INSTEAD OF DATAFRAME. NOT USED RIGHT NOW\n",
      "#general comment (Kate): there are functions below(ie SplitStatebyDot) which could have made this portion easier\n",
      "#but I didn't make them until I was done with this portion. \n",
      "\n",
      "#iterate through years\n",
      "for year in [2012, 2010, 2008, 2006, 2004, 2002]:\n",
      "    #create dataframe\n",
      "    url=urllist[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    \n",
      "    #create dictionary for info on each state\n",
      "    #each year needs own case b/c original tables formatted differently; combined to reuse code wherever possible \n",
      "    \n",
      "    if (year==2012):\n",
      "        colnames=dict(zip(table.columns, table.ix[2,:]))#change column names \n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True) #remove first and last few rows\n",
      "        table.drop(range(572,580)) \n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #remove extra nan columns\n",
      "        stateDictRace=dict(zip([table.ix[11*i,0] for i in range(52)], [table[11*i:11*(i+1)] for i in range(52)]))\n",
      "            \n",
      "    elif year==2010:\n",
      "        colnames=dict(zip(table.columns, table.ix[1,:]))#not analagous for years\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True) #also not analagous\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0, 'STATE']='All'\n",
      "        for i in range(52):\n",
      "               stateDictRace[table.ix[11*i,0]]=[stateDictRace[table.ix[11*i,0]], table[11*i:11*(i+1)]] #modify the dictionary\n",
      "                \n",
      "    elif (year==2008)|(year==2006)|(year==2004)|(year==2002):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        changeCol=dict(zip(table.columns, table.ix[4,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)#ditto this part\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        if year==2002:\n",
      "            for i in range(52):\n",
      "                table.ix[0, 'STATE']='All'\n",
      "                existinglist=stateDictRace[table.ix[10*i,0]]#modify the dictionary again\n",
      "                existinglist.append(table[10*i:10*(i+1)])\n",
      "                stateDictRace[table.ix[10*i,0]]=existinglist\n",
      "        else:\n",
      "            table.ix[0, 'State, sex, race, and Hispanic origin']='All'\n",
      "        if year==2004:\n",
      "            table=table.drop([43]).reset_index(drop=True)#one state has a duplicate row\n",
      "            for i in range(49): #something weird - don't have data for all states in 2004 (missing West Virginia, Wymoning, Wisconsin?)\n",
      "                existinglist=stateDictRace[table.ix[13*i,0]]\n",
      "                existinglist.append(table[13*i:13*(i+1)])\n",
      "                stateDictRace[table.ix[13*i,0]]=existinglist\n",
      "        elif (year==2006)|(year==2008):\n",
      "            for i in range(52):\n",
      "                existinglist=stateDictRace[table.ix[12*i,0]]\n",
      "                existinglist.append(table[12*i:12*(i+1)])\n",
      "                stateDictRace[table.ix[12*i,0]]=existinglist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 657: expected 13 fields, saw 24\n",
        "Skipping line 658: expected 13 fields, saw 24\n",
        "Skipping line 659: expected 13 fields, saw 24\n",
        "Skipping line 660: expected 13 fields, saw 24\n",
        "Skipping line 661: expected 13 fields, saw 24\n",
        "Skipping line 662: expected 13 fields, saw 24\n",
        "Skipping line 663: expected 13 fields, saw 24\n",
        "Skipping line 664: expected 13 fields, saw 24\n",
        "Skipping line 665: expected 13 fields, saw 24\n",
        "Skipping line 666: expected 13 fields, saw 24\n",
        "Skipping line 667: expected 13 fields, saw 24\n",
        "Skipping line 668: expected 13 fields, saw 24\n",
        "Skipping line 669: expected 13 fields, saw 24\n",
        "Skipping line 670: expected 13 fields, saw 24\n",
        "Skipping line 671: expected 13 fields, saw 24\n",
        "Skipping line 672: expected 13 fields, saw 24\n",
        "Skipping line 673: expected 13 fields, saw 37\n",
        "Skipping line 674: expected 13 fields, saw 37\n",
        "Skipping line 675: expected 13 fields, saw 37\n",
        "Skipping line 676: expected 13 fields, saw 37\n",
        "Skipping line 677: expected 13 fields, saw 37\n",
        "Skipping line 678: expected 13 fields, saw 37\n",
        "Skipping line 679: expected 13 fields, saw 37\n",
        "Skipping line 680: expected 13 fields, saw 37\n",
        "Skipping line 681: expected 13 fields, saw 37\n",
        "Skipping line 682: expected 13 fields, saw 37\n",
        "Skipping line 683: expected 13 fields, saw 37\n",
        "Skipping line 684: expected 13 fields, saw 37\n",
        "Skipping line 685: expected 13 fields, saw 37\n",
        "Skipping line 686: expected 13 fields, saw 37\n",
        "Skipping line 687: expected 13 fields, saw 37\n",
        "Skipping line 688: expected 13 fields, saw 37\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this function takes in a table where states are distinguished from demographic information by a dot (.) in front of the latter, returning a list of states and a list of tables for each state\n",
      "def splitbyStateDot(table):\n",
      "    indices=pd.DataFrame([item[0]=='.' for item in table[table.columns[0]][0:(len(table)-5)]])#trying to find states automatically\n",
      "    indices=indices.append([False, False, False, False, False]).reset_index(drop=True)\n",
      "    firstcol=table[table.columns[0]].reset_index(drop=True)\n",
      "    statesLoc=firstcol[indices[0]==False].index\n",
      "    return [item for item in firstcol[indices[0]==False]], [table.ix[statesLoc[i]:(statesLoc[i+1]-1), :] for i in range(len(statesLoc)-1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this function takes in a table where states are distinguished from demographic information by nan in front of the latter, returning a list of states and a list of tables for each state\n",
      "\n",
      "def splitbyStateNull(table):\n",
      "    indices=table[table.columns[0]].isnull()\n",
      "    indices[len(indices)-5:len(indices)]=False\n",
      "    firstcol=table[table.columns[0]]\n",
      "    statesLoc=firstcol[indices==False].index\n",
      "    return [item for item in firstcol[indices==False]], [table.ix[statesLoc[i]:(statesLoc[i+1]-1), :] for i in range(len(statesLoc)-1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#urls for Voting registration by AGE, for States, for years 2002, 2004, 2008, 2010, 2012\n",
      "#NOTE: Missing the year 2006 due to a gap in the data\n",
      "url2_2012 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2012/Table04c.csv'\n",
      "url2_2010 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2010/Table4c_2010.csv'\n",
      "url2_2008 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2008/Table%2004c.csv'\n",
      "url2_2006 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2006/tab04a.csv'\n",
      "url2_2004 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04b.csv'\n",
      "url2_2002 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2002/tab04b.csv'\n",
      "urllist2=[url2_2012, url2_2010, url2_2008, url2_2006, url2_2004, url2_2002]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Defines stateDictAge and stateDictRace\n",
      "\n",
      "for year in [2012, 2010, 2008, 2006, 2004]:\n",
      "    url=urllist2[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    if (year==2012):\n",
      "        changeCol=dict(zip(table.columns, table.ix[2,:]))#change the columns to match what we want them to be \n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        states, stateTable=splitbyStateNull(table)#getting states and tables for each state\n",
      "        stateDictAge=dict(zip(states[0:52],stateTable[0:52]))#making a dictionary for them\n",
      "    elif year==2010:\n",
      "        table.ix[1, table.columns[1]]=table.ix[2, table.columns[1]]#dealing with nan entry\n",
      "        changeCol=dict(zip(table.columns, table.ix[1,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        states, stateTable=splitbyStateNull(table) \n",
      "        for i in range(len(stateDictAge.keys())):#modifying the dictionary to include this year\n",
      "            existinglist=stateDictAge[states[i]]\n",
      "            existinglist=[existinglist, stateTable[i]]\n",
      "            stateDictAge[states[i]]=existinglist\n",
      "    elif (year==2008)|(year==2006)|(year==2004):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        changeCol=dict(zip(table.columns, table.ix[4,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)#ditto this part\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]#removes null columns\n",
      "        table=table[~pd.isnull(table[table.columns[0]])]#removes null rows\n",
      "        table.ix[0, table.columns[0]]='US'#one entry header not the same as previous years\n",
      "        states, stateTable=splitbyStateDot(table)\n",
      "        splitStates=[item.split(' ') for item in states]#removing random 2s in this year's table\n",
      "        states=[' '.join([i for i in item if not i.isdigit()]) for item in splitStates]\n",
      "        for i in range(len(stateDictAge.keys())):#modifying the dictionary again\n",
      "            existinglist=stateDictAge[states[i]]\n",
      "            existinglist.append(stateTable[i])\n",
      "            stateDictRace[states[i]]=existinglist\n",
      "    if year==2006:\n",
      "        print 'I could not find data for 2006, so this is 2004 instead.'\n",
      "    if year==2004:\n",
      "        print 'Similarly, 2004 is actually 2002.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I could not find data for 2006, so this is 2004 instead.\n",
        "Similarly, 2004 is actually 2002."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}