{
 "metadata": {
  "name": "",
  "signature": "sha256:83ac09b3d099ec5861df279bb6326374df621f46d12eb797a6604093fe6de36c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, zipfile, StringIO\n",
      "import pandas as pd\n",
      "from pandas import DataFrame, read_csv\n",
      "import math\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#urls for Voting registration by Sex, Race and Hispanic Origin, for States \n",
      "url_2012 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2012/Table04b.csv'\n",
      "url_2010 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2010/Table4b_2010.csv'\n",
      "url_2008 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2008/Table%2004b.csv'\n",
      "url_2006 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2006/tab04b.csv'\n",
      "url_2004 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04a.csv'\n",
      "url_2002 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2002/tab04a.csv'\n",
      "urllist=[url_2012, url_2010, url_2008, url_2006, url_2004, url_2002]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#IGNORE ME\n",
      "url = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04a.csv'\n",
      "table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "\n",
      "table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "colnames=dict(zip(table.columns, table.ix[4,:]))\n",
      "table.rename(columns=colnames, inplace=True)\n",
      "table=table.drop([0,1,2,3,4]).reset_index(drop=True)\n",
      "table.ix[0,0]='All'\n",
      "table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "table=table.ix[:,[0,1,2,5,6,7,8,9,10]]\n",
      "table.columns=df.columns[[1,2,3,4,5,6,9,10,11]]\n",
      "table['Year'] = year\n",
      "table['Percent registered\\\\(Citizen)']='nan'\n",
      "table['Margin of Error2']='nan'\n",
      "table['Percent voted\\\\(Citizen)']='nan'\n",
      "table['Margin of Error4']='nan'\n",
      "table['State']='nan'\n",
      "table=table.drop([43]).reset_index(drop=True)#one state has a duplicate row\n",
      "for i in range(49):      \n",
      "    table[13*i:13*(i+1)]['State'] = table.ix[13*i]['Race and Hispanic origin']\n",
      "table = table[df.columns]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 657: expected 13 fields, saw 24\n",
        "Skipping line 658: expected 13 fields, saw 24\n",
        "Skipping line 659: expected 13 fields, saw 24\n",
        "Skipping line 660: expected 13 fields, saw 24\n",
        "Skipping line 661: expected 13 fields, saw 24\n",
        "Skipping line 662: expected 13 fields, saw 24\n",
        "Skipping line 663: expected 13 fields, saw 24\n",
        "Skipping line 664: expected 13 fields, saw 24\n",
        "Skipping line 665: expected 13 fields, saw 24\n",
        "Skipping line 666: expected 13 fields, saw 24\n",
        "Skipping line 667: expected 13 fields, saw 24\n",
        "Skipping line 668: expected 13 fields, saw 24\n",
        "Skipping line 669: expected 13 fields, saw 24\n",
        "Skipping line 670: expected 13 fields, saw 24\n",
        "Skipping line 671: expected 13 fields, saw 24\n",
        "Skipping line 672: expected 13 fields, saw 24\n",
        "Skipping line 673: expected 13 fields, saw 37\n",
        "Skipping line 674: expected 13 fields, saw 37\n",
        "Skipping line 675: expected 13 fields, saw 37\n",
        "Skipping line 676: expected 13 fields, saw 37\n",
        "Skipping line 677: expected 13 fields, saw 37\n",
        "Skipping line 678: expected 13 fields, saw 37\n",
        "Skipping line 679: expected 13 fields, saw 37\n",
        "Skipping line 680: expected 13 fields, saw 37\n",
        "Skipping line 681: expected 13 fields, saw 37\n",
        "Skipping line 682: expected 13 fields, saw 37\n",
        "Skipping line 683: expected 13 fields, saw 37\n",
        "Skipping line 684: expected 13 fields, saw 37\n",
        "Skipping line 685: expected 13 fields, saw 37\n",
        "Skipping line 686: expected 13 fields, saw 37\n",
        "Skipping line 687: expected 13 fields, saw 37\n",
        "Skipping line 688: expected 13 fields, saw 37\n",
        "\n"
       ]
      },
      {
       "ename": "KeyError",
       "evalue": "\"[u'Percent registered\\\\n(Citizen)' u'Percent voted\\\\n(Citizen)'] not in index\"",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-239-5d2572124f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'State'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Race and Hispanic origin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/neha2/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/neha2/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1720\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/neha2/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: \"[u'Percent registered\\\\n(Citizen)' u'Percent voted\\\\n(Citizen)'] not in index\""
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#DIFFERENT VERSION OF NEXT BOX: CREATES ONE LARGE DATAFRAME INSTEAD\n",
      "#http://www.ncsl.org/research/elections-and-campaigns/voter-id-history.aspx\n",
      "#TOTAL VOTER INCLUDES NON CITIZENS (BOTH 18+)\n",
      "#WE'RE WORKING WITH CITIZENS\n",
      "\n",
      "#iterate through years\n",
      "for year in [2012, 2010, 2008, 2006]:\n",
      "    \n",
      "    #create dataframe\n",
      "    url=urllist[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    \n",
      "    #create large dataframe\n",
      "    #each year needs own case b/c original tables formatted differently; combined to reuse code wherever possible \n",
      "    \n",
      "    if year==2012:\n",
      "        changeCol=dict(zip(table.columns, table.ix[2,:]))#change the columns to match what we want them to be \n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True)\n",
      "        table=table[table.index < 572] # we don't want first or last few rows\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        table['Year'] = year\n",
      "        for i in range(52):\n",
      "            table[11*i:11*(i+1)]['State'] = table.ix[11*i]['State']\n",
      "        df=table\n",
      "        df.columns=['State', u'Race and Hispanic origin', u'Total Population', u'Total Citizen Population', u'Total registered', u'Percent registered\\n(Total)', u'Margin of Error1', u'Percent registered\\n(Citizen)', u'Margin of Error2', u'Total voted', u'Percent voted\\n(Total)', u'Margin of Error3', u'Percent voted\\n(Citizen)', u'Margin of Error4', u'Year']\n",
      "    \n",
      "    elif year==2010:\n",
      "        table.ix[1, 1]='Race and Hispanic origin'\n",
      "        colnames=dict(zip(table.columns, table.ix[1,:]))#not analagous for years\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True) #also not analagous\n",
      "        table=table[table.index < 572]\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table['Year'] = year\n",
      "        table.ix[0, 'STATE']='All'\n",
      "        for i in range(52):\n",
      "            table[11*i:11*(i+1)]['STATE'] = table.ix[11*i]['STATE']\n",
      "        table.columns = df.columns\n",
      "        df = pd.concat([table,df])\n",
      "    \n",
      "    elif (year==2008)|(year==2006):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        colnames=dict(zip(table.columns, table.ix[4,:]))\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)\n",
      "        table.ix[0,0]='All'\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table['Year'] = year\n",
      "        table.columns=df.columns[1:15]\n",
      "        table['State']='nan'\n",
      "        for i in range(52):      \n",
      "            table[12*i:12*(i+1)]['State'] = table.ix[12*i]['Race and Hispanic origin']   \n",
      "        #delete every 12th row starting from first\n",
      "        cols = table.columns.tolist()\n",
      "        cols = cols[-1:] + cols[:-1]\n",
      "        table = table[cols]\n",
      "        df = pd.concat([table,df])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['law']='nan'\n",
      "\n",
      "#voterid conditions\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#general comment (Kate): there are functions below(ie SplitStatebyDot) which could have made this portion easier\n",
      "#but I didn't make them until I was done with this portion. \n",
      "\n",
      "#iterate through years\n",
      "for year in [2012, 2010, 2008, 2006, 2004, 2002]:\n",
      "    #create dataframe\n",
      "    url=urllist[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    \n",
      "    #create dictionary for info on each state\n",
      "    #each year needs own case b/c original tables formatted differently; combined to reuse code wherever possible \n",
      "    \n",
      "    if (year==2012):\n",
      "        colnames=dict(zip(table.columns, table.ix[2,:]))#change column names \n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True) #remove first and last few rows\n",
      "        table.drop(range(572,580)) \n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #remove extra nan columns\n",
      "        stateDictRace=dict(zip([table.ix[11*i,0] for i in range(52)], [table[11*i:11*(i+1)] for i in range(52)]))\n",
      "            \n",
      "    elif year==2010:\n",
      "        colnames=dict(zip(table.columns, table.ix[1,:]))#not analagous for years\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True) #also not analagous\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0, 'STATE']='All'\n",
      "        for i in range(52):\n",
      "               stateDictRace[table.ix[11*i,0]]=[stateDictRace[table.ix[11*i,0]], table[11*i:11*(i+1)]] #modify the dictionary\n",
      "                \n",
      "    elif (year==2008)|(year==2006)|(year==2004)|(year==2002):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        changeCol=dict(zip(table.columns, table.ix[4,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)#ditto this part\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        if year==2002:\n",
      "            for i in range(52):\n",
      "                table.ix[0, 'STATE']='All'\n",
      "                existinglist=stateDictRace[table.ix[10*i,0]]#modify the dictionary again\n",
      "                existinglist.append(table[10*i:10*(i+1)])\n",
      "                stateDictRace[table.ix[10*i,0]]=existinglist\n",
      "        else:\n",
      "            table.ix[0, 'State, sex, race, and Hispanic origin']='All'\n",
      "        if year==2004:\n",
      "            table=table.drop([43]).reset_index(drop=True)#one state has a duplicate row\n",
      "            for i in range(49): #something weird - don't have data for all states in 2004 (missing West Virginia, Wymoning, Wisconsin?)\n",
      "                existinglist=stateDictRace[table.ix[13*i,0]]\n",
      "                existinglist.append(table[13*i:13*(i+1)])\n",
      "                stateDictRace[table.ix[13*i,0]]=existinglist\n",
      "        elif (year==2006)|(year==2008):\n",
      "            for i in range(52):\n",
      "                existinglist=stateDictRace[table.ix[12*i,0]]\n",
      "                existinglist.append(table[12*i:12*(i+1)])\n",
      "                stateDictRace[table.ix[12*i,0]]=existinglist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 657: expected 13 fields, saw 24\n",
        "Skipping line 658: expected 13 fields, saw 24\n",
        "Skipping line 659: expected 13 fields, saw 24\n",
        "Skipping line 660: expected 13 fields, saw 24\n",
        "Skipping line 661: expected 13 fields, saw 24\n",
        "Skipping line 662: expected 13 fields, saw 24\n",
        "Skipping line 663: expected 13 fields, saw 24\n",
        "Skipping line 664: expected 13 fields, saw 24\n",
        "Skipping line 665: expected 13 fields, saw 24\n",
        "Skipping line 666: expected 13 fields, saw 24\n",
        "Skipping line 667: expected 13 fields, saw 24\n",
        "Skipping line 668: expected 13 fields, saw 24\n",
        "Skipping line 669: expected 13 fields, saw 24\n",
        "Skipping line 670: expected 13 fields, saw 24\n",
        "Skipping line 671: expected 13 fields, saw 24\n",
        "Skipping line 672: expected 13 fields, saw 24\n",
        "Skipping line 673: expected 13 fields, saw 37\n",
        "Skipping line 674: expected 13 fields, saw 37\n",
        "Skipping line 675: expected 13 fields, saw 37\n",
        "Skipping line 676: expected 13 fields, saw 37\n",
        "Skipping line 677: expected 13 fields, saw 37\n",
        "Skipping line 678: expected 13 fields, saw 37\n",
        "Skipping line 679: expected 13 fields, saw 37\n",
        "Skipping line 680: expected 13 fields, saw 37\n",
        "Skipping line 681: expected 13 fields, saw 37\n",
        "Skipping line 682: expected 13 fields, saw 37\n",
        "Skipping line 683: expected 13 fields, saw 37\n",
        "Skipping line 684: expected 13 fields, saw 37\n",
        "Skipping line 685: expected 13 fields, saw 37\n",
        "Skipping line 686: expected 13 fields, saw 37\n",
        "Skipping line 687: expected 13 fields, saw 37\n",
        "Skipping line 688: expected 13 fields, saw 37\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this function takes in a table where states are distinguished from demographic information by a dot (.) in front of the latter, returning a list of states and a list of tables for each state\n",
      "def splitbyStateDot(table):\n",
      "    indices=pd.DataFrame([item[0]=='.' for item in table[table.columns[0]][0:(len(table)-5)]])#trying to find states automatically\n",
      "    indices=indices.append([False, False, False, False, False]).reset_index(drop=True)\n",
      "    firstcol=table[table.columns[0]].reset_index(drop=True)\n",
      "    statesLoc=firstcol[indices[0]==False].index\n",
      "    return [item for item in firstcol[indices[0]==False]], [table.ix[statesLoc[i]:(statesLoc[i+1]-1), :] for i in range(len(statesLoc)-1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this function takes in a table where states are distinguished from demographic information by nan in front of the latter, returning a list of states and a list of tables for each state\n",
      "\n",
      "def splitbyStateNull(table):\n",
      "    indices=table[table.columns[0]].isnull()\n",
      "    indices[len(indices)-5:len(indices)]=False\n",
      "    firstcol=table[table.columns[0]]\n",
      "    statesLoc=firstcol[indices==False].index\n",
      "    return [item for item in firstcol[indices==False]], [table.ix[statesLoc[i]:(statesLoc[i+1]-1), :] for i in range(len(statesLoc)-1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#urls for Voting registration by AGE, for States, for years 2002, 2004, 2008, 2010, 2012\n",
      "#NOTE: Missing the year 2006 due to a gap in the data\n",
      "url2_2012 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2012/Table04c.csv'\n",
      "url2_2010 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2010/Table4c_2010.csv'\n",
      "url2_2008 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2008/Table%2004c.csv'\n",
      "url2_2006 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2006/tab04a.csv'\n",
      "url2_2004 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04b.csv'\n",
      "url2_2002 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2002/tab04b.csv'\n",
      "urllist2=[url2_2012, url2_2010, url2_2008, url2_2006, url2_2004, url2_2002]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Defines stateDictAge and stateDictRace\n",
      "\n",
      "for year in [2012, 2010, 2008, 2006, 2004]:\n",
      "    url=urllist2[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    if (year==2012):\n",
      "        changeCol=dict(zip(table.columns, table.ix[2,:]))#change the columns to match what we want them to be \n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        states, stateTable=splitbyStateNull(table)#getting states and tables for each state\n",
      "        stateDictAge=dict(zip(states[0:52],stateTable[0:52]))#making a dictionary for them\n",
      "    elif year==2010:\n",
      "        table.ix[1, table.columns[1]]=table.ix[2, table.columns[1]]#dealing with nan entry\n",
      "        changeCol=dict(zip(table.columns, table.ix[1,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        states, stateTable=splitbyStateNull(table) \n",
      "        for i in range(len(stateDictAge.keys())):#modifying the dictionary to include this year\n",
      "            existinglist=stateDictAge[states[i]]\n",
      "            existinglist=[existinglist, stateTable[i]]\n",
      "            stateDictAge[states[i]]=existinglist\n",
      "    elif (year==2008)|(year==2006)|(year==2004):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        changeCol=dict(zip(table.columns, table.ix[4,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)#ditto this part\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]#removes null columns\n",
      "        table=table[~pd.isnull(table[table.columns[0]])]#removes null rows\n",
      "        table.ix[0, table.columns[0]]='US'#one entry header not the same as previous years\n",
      "        states, stateTable=splitbyStateDot(table)\n",
      "        splitStates=[item.split(' ') for item in states]#removing random 2s in this year's table\n",
      "        states=[' '.join([i for i in item if not i.isdigit()]) for item in splitStates]\n",
      "        for i in range(len(stateDictAge.keys())):#modifying the dictionary again\n",
      "            existinglist=stateDictAge[states[i]]\n",
      "            existinglist.append(stateTable[i])\n",
      "            stateDictRace[states[i]]=existinglist\n",
      "    if year==2006:\n",
      "        print 'I could not find data for 2006, so this is 2004 instead.'\n",
      "    if year==2004:\n",
      "        print 'Similarly, 2004 is actually 2002.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I could not find data for 2006, so this is 2004 instead.\n",
        "Similarly, 2004 is actually 2002."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Everything below this point is *only for debugging* - don't worry if it doesn't work. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}