{
 "metadata": {
  "name": "",
  "signature": "sha256:5b0285cb010b79b1f843f8dc63e201a6f2cf218d03305cda1cea784cef5ece25"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, zipfile, StringIO\n",
      "import pandas as pd\n",
      "from pandas import DataFrame, read_csv\n",
      "import math\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#urls for Voting registration by Sex, Race and Hispanic Origin, for States \n",
      "url_2012 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2012/Table04b.csv'\n",
      "url_2010 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2010/Table4b_2010.csv'\n",
      "url_2008 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2008/Table%2004b.csv'\n",
      "url_2006 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2006/tab04b.csv'\n",
      "url_2004 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04a.csv'\n",
      "url_2002 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2002/tab04a.csv'\n",
      "urllist=[url_2012, url_2010, url_2008, url_2006, url_2004, url_2002]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Combines datasets to create dataframe of state/year rows\n",
      "#TOTAL VOTER INCLUDES NON CITIZENS (BOTH 18+)\n",
      "#WE'RE WORKING WITH CITIZENS\n",
      "\n",
      "#iterate through years\n",
      "for year in [2012, 2010, 2008, 2006, 2004, 2002]:\n",
      "    \n",
      "    #create dataframe\n",
      "    url=urllist[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    table['Year'] = year #create year column\n",
      "    \n",
      "    #create large dataframe\n",
      "    #each year needs own case b/c original tables formatted differently; combined to reuse code wherever possible \n",
      "    \n",
      "    if year==2012:\n",
      "        changeCol=dict(zip(table.columns, table.ix[2,:])) #change the columns to match what we want them to be \n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True)\n",
      "        table=table[table.index < 572] #we don't want first or last few rows\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        state = [] #initialize state array to use later\n",
      "        for i in range(52): #create state column\n",
      "            table[11*i:11*(i+1)]['State'] = table.ix[11*i]['State']\n",
      "            state.append(table.ix[11*i]['State']) #append to state array\n",
      "        df=table\n",
      "        df.columns=['State', 'Race and Hispanic origin', 'Total Population', 'Total Citizen Population', 'Total registered', 'Percent registered\\n(Total)', 'Margin of Error1', 'Percent registered\\n(Citizen)', 'Margin of Error2', 'Total voted', 'Percent voted\\n(Total)', 'Margin of Error3', 'Percent voted\\n(Citizen)', 'Margin of Error4', 'Year']\n",
      "            #rename columns\n",
      "            \n",
      "    elif year==2010:\n",
      "        table.ix[1, 1]='Race and Hispanic origin'\n",
      "        colnames=dict(zip(table.columns, table.ix[1,:]))#not analagous for years\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True) #also not analagous\n",
      "        table=table[table.index < 572]\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0, 0]='All'\n",
      "        for i in range(52):\n",
      "            table[11*i:11*(i+1)]['STATE'] = table.ix[11*i]['STATE']\n",
      "        table.columns = df.columns #rename columns\n",
      "        df = pd.concat([table,df]) #concat w/ dataframe\n",
      "    \n",
      "    elif (year==2008)|(year==2006)|(year==2004)|(year==2002):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        colnames=dict(zip(table.columns, table.ix[4,:]))\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0,0]='All'\n",
      "       \n",
      "        if (year==2008)|(year==2006):\n",
      "            table.columns=df.columns[1:15]\n",
      "            table['State']='nan'\n",
      "            for i in range(52):      \n",
      "                table[12*i:12*(i+1)]['State'] = table.ix[12*i]['Race and Hispanic origin']   \n",
      "            #delete every 12th row starting from first\n",
      "        \n",
      "        elif (year==2004)|(year==2002):\n",
      "            table=table.iloc[:,[0,1,2,5,6,7,8,9,10,11]] #delete useless columns\n",
      "            table.columns=df.columns[[1,2,3,4,5,6,9,10,11,14]] #name columns appropriately\n",
      "            table['Percent registered\\n(Citizen)']='nan' #create missing columns\n",
      "            table['Margin of Error2']='nan'\n",
      "            table['Percent voted\\n(Citizen)']='nan'\n",
      "            table['Margin of Error4']='nan'\n",
      "            table['State']='nan'\n",
      "            \n",
      "            if year==2004:\n",
      "                table=table.drop([43]).reset_index(drop=True) #one state has a duplicate row        \n",
      "                for i in range(49): #something weird - don't have data for all states in 2004 (missing West Virginia, Wymoning, Wisconsin?)\n",
      "                    table[13*i:13*(i+1)]['State'] = table.ix[13*i]['Race and Hispanic origin']\n",
      "            \n",
      "            elif year==2002:\n",
      "                for i in range(52):\n",
      "                    table[10*i:10*(i+1)]['State'] = table.ix[10*i]['Race and Hispanic origin']\n",
      "        \n",
      "        table = table[df.columns]\n",
      "        df = pd.concat([table,df])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 657: expected 13 fields, saw 24\n",
        "Skipping line 658: expected 13 fields, saw 24\n",
        "Skipping line 659: expected 13 fields, saw 24\n",
        "Skipping line 660: expected 13 fields, saw 24\n",
        "Skipping line 661: expected 13 fields, saw 24\n",
        "Skipping line 662: expected 13 fields, saw 24\n",
        "Skipping line 663: expected 13 fields, saw 24\n",
        "Skipping line 664: expected 13 fields, saw 24\n",
        "Skipping line 665: expected 13 fields, saw 24\n",
        "Skipping line 666: expected 13 fields, saw 24\n",
        "Skipping line 667: expected 13 fields, saw 24\n",
        "Skipping line 668: expected 13 fields, saw 24\n",
        "Skipping line 669: expected 13 fields, saw 24\n",
        "Skipping line 670: expected 13 fields, saw 24\n",
        "Skipping line 671: expected 13 fields, saw 24\n",
        "Skipping line 672: expected 13 fields, saw 24\n",
        "Skipping line 673: expected 13 fields, saw 37\n",
        "Skipping line 674: expected 13 fields, saw 37\n",
        "Skipping line 675: expected 13 fields, saw 37\n",
        "Skipping line 676: expected 13 fields, saw 37\n",
        "Skipping line 677: expected 13 fields, saw 37\n",
        "Skipping line 678: expected 13 fields, saw 37\n",
        "Skipping line 679: expected 13 fields, saw 37\n",
        "Skipping line 680: expected 13 fields, saw 37\n",
        "Skipping line 681: expected 13 fields, saw 37\n",
        "Skipping line 682: expected 13 fields, saw 37\n",
        "Skipping line 683: expected 13 fields, saw 37\n",
        "Skipping line 684: expected 13 fields, saw 37\n",
        "Skipping line 685: expected 13 fields, saw 37\n",
        "Skipping line 686: expected 13 fields, saw 37\n",
        "Skipping line 687: expected 13 fields, saw 37\n",
        "Skipping line 688: expected 13 fields, saw 37\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#THIS SHOULD BE MADE MORE ACCURATE IF SOMEONE IS BORED\n",
      "\n",
      "#http://www.ncsl.org/research/elections-and-campaigns/voter-id-history.aspx\n",
      "    #0 = no voter id law\n",
      "    #1 = not strict voter id law (w/ or w/out photo)\n",
      "    #2 = strict voter id law (w/ or w/out photo)\n",
      "#http://en.wikipedia.org/wiki/Voter_ID_laws_in_the_United_States\n",
      "#http://www.hartwick.edu/Documents/POSC/MeyerThesisSp13.pdf -- not completely synced with this source\n",
      "\n",
      "law_id=pd.DataFrame(columns=['State','non_strict_year', 'strict_year'])\n",
      "law_id['State'] = state[1:52]\n",
      "\n",
      "law_id.ix[0,1] = 2003\n",
      "law_id.ix[1,1] = 1980\n",
      "law_id.ix[2,2] = 2004 #check wiki article date: 2006?\n",
      "law_id.ix[5,1] = 2003\n",
      "law_id.ix[6,1] = 2010\n",
      "law_id.ix[7,1] = 2010\n",
      "law_id.ix[9,1] = 1977\n",
      "law_id.ix[10,[1,2]] = [1997,2008]\n",
      "law_id.ix[11,1] = 1970\n",
      "law_id.ix[12,1] = 2010\n",
      "law_id.ix[14,2] = 2008\n",
      "law_id.ix[16,2] = 2011\n",
      "law_id.ix[18,1] = 2010\n",
      "law_id.ix[22,1] = 2010\n",
      "law_id.ix[24,2] = 2012\n",
      "law_id.ix[25,1] = 2002\n",
      "law_id.ix[26,1] = 2003\n",
      "law_id.ix[29,1] = 2012\n",
      "law_id.ix[33,2] = 2016\n",
      "law_id.ix[34,[1,2]] = [2003,2013]\n",
      "law_id.ix[35,2] = 2006\n",
      "law_id.ix[36,1] = 2010\n",
      "law_id.ix[39,1] = 2013\n",
      "law_id.ix[40,[1,2]] = [1950,2013]\n",
      "law_id.ix[41,1] = 2003\n",
      "law_id.ix[42,[1,2]] = [1990,2011]\n",
      "law_id.ix[43,1] = 1971\n",
      "law_id.ix[44,1] = 2009\n",
      "law_id.ix[46,[1,2]] = [1996,2013]\n",
      "law_id.ix[47,1] = 2005"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "racedata = pd.merge(df, law_id, on = ['State'])\n",
      "\n",
      "#boolean shtuff\n",
      "racedata['status'] = 2 * (racedata['strict_year']<racedata['Year']).astype(int) + (racedata['non_strict_year']<racedata['Year']).astype(int) \n",
      "\n",
      "#Change 3's to 2's to make up for the fact that we added states that had both strict and non strict id laws twice\n",
      "for row in racedata.index:\n",
      "    if racedata.ix[row,'status'] == 3:\n",
      "        racedata.ix[row,'status'] = 2\n",
      "\n",
      "#DATA CLEANING\n",
      "#Remove periods from beginning of entries in 'Race and Hispanic Origin'\n",
      "racedata['Race and Hispanic origin'] = racedata['Race and Hispanic origin'].map(lambda x: x.replace('.','')) \n",
      "\n",
      "racedata['Percent of registered who voted'] = ['nan' for i in range(len(racedata.index))]\n",
      "\n",
      "#Change non float entries to 'nan'\n",
      "for row in racedata.index:\n",
      "    for col in range(2, len(racedata.columns)):\n",
      "        try:\n",
      "            float(racedata.ix[row, col])\n",
      "            racedata[row, 'Percent of registered who voted'] = 0 #racedata[row,'Percent voted\\n(Total)'] / racedata[row,'Percent registered\\n(Total)'] *100\n",
      "        except ValueError:\n",
      "            racedata.ix[row, col] = 'nan' \n",
      "        #if racedata.ix[row, col] ==  '(B)' or racedata.ix[row, col] ==  '(B) ':\n",
      "        #    racedata.ix[row, col] = 'nan' \n",
      "            \n",
      "racedata.head(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "states = state[1:52]\n",
      "\n",
      "for state in states:\n",
      "    statedata = racedata.groupby('State').get_group(state)\n",
      "    subgroup = [0 for i in range(5)]\n",
      "    subgroup[0] = statedata.groupby('Race and Hispanic origin').get_group('Total')\n",
      "    subgroup[1] = statedata.groupby('Race and Hispanic origin').get_group('Non-Hispanic White')\n",
      "    subgroup[2] = statedata.groupby('Race and Hispanic origin').get_group('Non-Hispanic Black')\n",
      "    subgroup[3] = statedata.groupby('Race and Hispanic origin').get_group('Asian and Pacific Islander')\n",
      "    subgroup[4] = statedata.groupby('Race and Hispanic origin').get_group('Hispanic (of any race)')\n",
      "\n",
      "    #Alternate names\n",
      "    subgroup2 = [0 for i in range(5)]\n",
      "    subgroup2[0] = statedata.groupby('Race and Hispanic origin').get_group('Total')\n",
      "    subgroup2[1] = statedata.groupby('Race and Hispanic origin').get_group('White non-Hispanic alone')\n",
      "    subgroup2[2] = statedata.groupby('Race and Hispanic origin').get_group('Black alone')\n",
      "    subgroup2[3] = statedata.groupby('Race and Hispanic origin').get_group('Asian alone')\n",
      "    subgroup2[4] = statedata.groupby('Race and Hispanic origin').get_group('Hispanic (of any race)')\n",
      "\n",
      "    colors = ['black','blue','yellow','green','red']\n",
      "    \n",
      "    for elt in ['Percent registered\\n(Total)', 'Percent voted\\n(Total)']:\n",
      "        graph = []\n",
      "        for i in range(5):\n",
      "             graph.append( plt.scatter(x = subgroup[i]['Year'], y = subgroup[i][elt], c = colors[i]) )\n",
      "             plt.scatter(x = subgroup2[i]['Year'], y = subgroup2[i][x], c = colors[i])\n",
      "        #gra = plt.scatter(x = subgroup2['Year'], y = subgroup2['Percent registered\\n(Total)'], c = 'g')\n",
      "\n",
      "        plt.title(state + \" PERCENT REGISTERED BY RACE\")\n",
      "        plt.xlabel(\"Year\")\n",
      "        plt.ylabel(\"Percent Registered of Total Pop.\")\n",
      "\n",
      "        plt.xlim(2000,2014)\n",
      "        plt.legend((graph), ('All groups', 'White', 'Black', 'Asian', 'Hispanic'), scatterpoints=1,loc = 'lower left')\n",
      "        plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#MAKES DICTIONARY INSTEAD OF DATAFRAME. NOT USED RIGHT NOW\n",
      "#general comment (Kate): there are functions below(ie SplitStatebyDot) which could have made this portion easier\n",
      "#but I didn't make them until I was done with this portion. \n",
      "\n",
      "#iterate through years\n",
      "for year in [2012, 2010, 2008, 2006, 2004, 2002]:\n",
      "    #create dataframe\n",
      "    url=urllist[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    \n",
      "    #create dictionary for info on each state\n",
      "    #each year needs own case b/c original tables formatted differently; combined to reuse code wherever possible \n",
      "    \n",
      "    if (year==2012):\n",
      "        colnames=dict(zip(table.columns, table.ix[2,:]))#change column names \n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True) #remove first and last few rows\n",
      "        table.drop(range(572,580)) \n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #remove extra nan columns\n",
      "        stateDictRace=dict(zip([table.ix[11*i,0] for i in range(52)], [table[11*i:11*(i+1)] for i in range(52)]))\n",
      "            \n",
      "    elif year==2010:\n",
      "        colnames=dict(zip(table.columns, table.ix[1,:]))#not analagous for years\n",
      "        table.rename(columns=colnames, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True) #also not analagous\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]\n",
      "        table.ix[0, 'STATE']='All'\n",
      "        for i in range(52):\n",
      "               stateDictRace[table.ix[11*i,0]]=[stateDictRace[table.ix[11*i,0]], table[11*i:11*(i+1)]] #modify the dictionary\n",
      "                \n",
      "    elif (year==2008)|(year==2006)|(year==2004)|(year==2002):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        changeCol=dict(zip(table.columns, table.ix[4,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)#ditto this part\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        if year==2002:\n",
      "            for i in range(52):\n",
      "                table.ix[0, 'STATE']='All'\n",
      "                existinglist=stateDictRace[table.ix[10*i,0]]#modify the dictionary again\n",
      "                existinglist.append(table[10*i:10*(i+1)])\n",
      "                stateDictRace[table.ix[10*i,0]]=existinglist\n",
      "        else:\n",
      "            table.ix[0, 'State, sex, race, and Hispanic origin']='All'\n",
      "        if year==2004:\n",
      "            table=table.drop([43]).reset_index(drop=True)#one state has a duplicate row\n",
      "            for i in range(49): #something weird - don't have data for all states in 2004 (missing West Virginia, Wymoning, Wisconsin?)\n",
      "                existinglist=stateDictRace[table.ix[13*i,0]]\n",
      "                existinglist.append(table[13*i:13*(i+1)])\n",
      "                stateDictRace[table.ix[13*i,0]]=existinglist\n",
      "        elif (year==2006)|(year==2008):\n",
      "            for i in range(52):\n",
      "                existinglist=stateDictRace[table.ix[12*i,0]]\n",
      "                existinglist.append(table[12*i:12*(i+1)])\n",
      "                stateDictRace[table.ix[12*i,0]]=existinglist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 657: expected 13 fields, saw 24\n",
        "Skipping line 658: expected 13 fields, saw 24\n",
        "Skipping line 659: expected 13 fields, saw 24\n",
        "Skipping line 660: expected 13 fields, saw 24\n",
        "Skipping line 661: expected 13 fields, saw 24\n",
        "Skipping line 662: expected 13 fields, saw 24\n",
        "Skipping line 663: expected 13 fields, saw 24\n",
        "Skipping line 664: expected 13 fields, saw 24\n",
        "Skipping line 665: expected 13 fields, saw 24\n",
        "Skipping line 666: expected 13 fields, saw 24\n",
        "Skipping line 667: expected 13 fields, saw 24\n",
        "Skipping line 668: expected 13 fields, saw 24\n",
        "Skipping line 669: expected 13 fields, saw 24\n",
        "Skipping line 670: expected 13 fields, saw 24\n",
        "Skipping line 671: expected 13 fields, saw 24\n",
        "Skipping line 672: expected 13 fields, saw 24\n",
        "Skipping line 673: expected 13 fields, saw 37\n",
        "Skipping line 674: expected 13 fields, saw 37\n",
        "Skipping line 675: expected 13 fields, saw 37\n",
        "Skipping line 676: expected 13 fields, saw 37\n",
        "Skipping line 677: expected 13 fields, saw 37\n",
        "Skipping line 678: expected 13 fields, saw 37\n",
        "Skipping line 679: expected 13 fields, saw 37\n",
        "Skipping line 680: expected 13 fields, saw 37\n",
        "Skipping line 681: expected 13 fields, saw 37\n",
        "Skipping line 682: expected 13 fields, saw 37\n",
        "Skipping line 683: expected 13 fields, saw 37\n",
        "Skipping line 684: expected 13 fields, saw 37\n",
        "Skipping line 685: expected 13 fields, saw 37\n",
        "Skipping line 686: expected 13 fields, saw 37\n",
        "Skipping line 687: expected 13 fields, saw 37\n",
        "Skipping line 688: expected 13 fields, saw 37\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this function takes in a table where states are distinguished from demographic information by a dot (.) in front of the latter, returning a list of states and a list of tables for each state\n",
      "def splitbyStateDot(table):\n",
      "    indices=pd.DataFrame([item[0]=='.' for item in table[table.columns[0]][0:(len(table)-5)]])#trying to find states automatically\n",
      "    indices=indices.append([False, False, False, False, False]).reset_index(drop=True)\n",
      "    firstcol=table[table.columns[0]].reset_index(drop=True)\n",
      "    statesLoc=firstcol[indices[0]==False].index\n",
      "    return [item for item in firstcol[indices[0]==False]], [table.ix[statesLoc[i]:(statesLoc[i+1]-1), :] for i in range(len(statesLoc)-1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this function takes in a table where states are distinguished from demographic information by nan in front of the latter, returning a list of states and a list of tables for each state\n",
      "\n",
      "def splitbyStateNull(table):\n",
      "    indices=table[table.columns[0]].isnull()\n",
      "    indices[len(indices)-5:len(indices)]=False\n",
      "    firstcol=table[table.columns[0]]\n",
      "    statesLoc=firstcol[indices==False].index\n",
      "    return [item for item in firstcol[indices==False]], [table.ix[statesLoc[i]:(statesLoc[i+1]-1), :] for i in range(len(statesLoc)-1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#urls for Voting registration by AGE, for States, for years 2002, 2004, 2008, 2010, 2012\n",
      "#NOTE: Missing the year 2006 due to a gap in the data\n",
      "url2_2012 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2012/Table04c.csv'\n",
      "url2_2010 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2010/Table4c_2010.csv'\n",
      "url2_2008 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2008/Table%2004c.csv'\n",
      "url2_2006 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2006/tab04a.csv'\n",
      "url2_2004 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2004/tab04b.csv'\n",
      "url2_2002 = 'http://www.census.gov/hhes/www/socdemo/voting/publications/p20/2002/tab04b.csv'\n",
      "urllist2=[url2_2012, url2_2010, url2_2008, url2_2006, url2_2004, url2_2002]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Defines stateDictAge and stateDictRace\n",
      "\n",
      "for year in [2012, 2010, 2008, 2006, 2004]:\n",
      "    url=urllist2[(2012-year)/2]\n",
      "    table=pd.read_csv(StringIO.StringIO(requests.get(url).content),error_bad_lines=False)\n",
      "    if (year==2012):\n",
      "        changeCol=dict(zip(table.columns, table.ix[2,:]))#change the columns to match what we want them to be \n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        states, stateTable=splitbyStateNull(table)#getting states and tables for each state\n",
      "        stateDictAge=dict(zip(states[0:52],stateTable[0:52]))#making a dictionary for them\n",
      "    elif year==2010:\n",
      "        table.ix[1, table.columns[1]]=table.ix[2, table.columns[1]]#dealing with nan entry\n",
      "        changeCol=dict(zip(table.columns, table.ix[1,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1]).reset_index(drop=True)\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))] #removing extra nan columns\n",
      "        states, stateTable=splitbyStateNull(table) \n",
      "        for i in range(len(stateDictAge.keys())):#modifying the dictionary to include this year\n",
      "            existinglist=stateDictAge[states[i]]\n",
      "            existinglist=[existinglist, stateTable[i]]\n",
      "            stateDictAge[states[i]]=existinglist\n",
      "    elif (year==2008)|(year==2006)|(year==2004):\n",
      "        table.ix[4,table.columns[0:3]]=table.ix[3,table.columns[0:3]]\n",
      "        changeCol=dict(zip(table.columns, table.ix[4,:]))#change the columns to match what we want them to be #this portion also not analgous for years\n",
      "        table.rename(columns=changeCol, inplace=True)\n",
      "        table=table.drop([0,1,2,3,4]).reset_index(drop=True)#ditto this part\n",
      "        table=table.ix[:,(~pd.isnull(table.columns))]#removes null columns\n",
      "        table=table[~pd.isnull(table[table.columns[0]])]#removes null rows\n",
      "        table.ix[0, table.columns[0]]='US'#one entry header not the same as previous years\n",
      "        states, stateTable=splitbyStateDot(table)\n",
      "        splitStates=[item.split(' ') for item in states]#removing random 2s in this year's table\n",
      "        states=[' '.join([i for i in item if not i.isdigit()]) for item in splitStates]\n",
      "        for i in range(len(stateDictAge.keys())):#modifying the dictionary again\n",
      "            existinglist=stateDictAge[states[i]]\n",
      "            existinglist.append(stateTable[i])\n",
      "            stateDictRace[states[i]]=existinglist\n",
      "    if year==2006:\n",
      "        print 'I could not find data for 2006, so this is 2004 instead.'\n",
      "    if year==2004:\n",
      "        print 'Similarly, 2004 is actually 2002.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I could not find data for 2006, so this is 2004 instead.\n",
        "Similarly, 2004 is actually 2002."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}